from py_captions_for_channels.logging.structured_logger import get_logger
import re
import subprocess
from typing import Callable, Optional
import time
from pathlib import Path
import sys

from .config import (
    LOG_DIVIDER_CHAR,
    LOG_DIVIDER_LENGTH,
    LOG_STATS_ENABLED,
    PIPELINE_TIMEOUT,
)


class PipelineResult:
    """Result of a pipeline execution."""

    def __init__(
        self,
        success: bool,
        returncode: int,
        stdout: str = "",
        stderr: str = "",
        command: str = "",
        elapsed_seconds: float = 0.0,
        output_files: dict = None,
        input_size_bytes: int = 0,
        input_path: str = "",
    ):
        self.success = success
        self.returncode = returncode
        self.stdout = stdout
        self.stderr = stderr
        self.command = command
        self.elapsed_seconds = elapsed_seconds
        self.output_files = output_files or {}  # Dict of {filename: size_bytes}
        self.input_size_bytes = input_size_bytes
        self.input_path = input_path
        self.is_dry_run = False  # Set to True for dry-run executions

    def get_total_output_size(self) -> int:
        """Return total size of all output files in bytes."""
        return sum(self.output_files.values())

    def format_size(self, bytes_size: int) -> str:
        """Format bytes to human-readable string."""
        for unit in ["B", "KB", "MB", "GB"]:
            if bytes_size < 1024.0:
                return f"{bytes_size:.1f} {unit}"
            bytes_size /= 1024.0
        return f"{bytes_size:.1f} TB"


class Pipeline:
    """Executes the captioning workflow.

    Supports dry-run mode for testing and captures stdout/stderr
    for debugging and logging.
    """

    def __init__(self, command_template: str, dry_run: bool = False):
        """Initialize pipeline.

        Args:
            command_template: Command template with {path} placeholder
            dry_run: If True, print commands instead of executing them
        """
        self.command_template = command_template
        self.dry_run = dry_run

    def _collect_output_files(self, recording_path: str) -> dict:
        """Collect statistics for output files generated by the command.

        Looks for:
        - .srt caption file (same directory/name as recording)
        - .mp4 transcoded file (if TRANSCODE_FOR_FIRETV=true)

        Args:
            recording_path: Path to the original recording file

        Returns:
            Dict of {filename: size_bytes} for generated files
        """
        output_files = {}
        recording_path = Path(recording_path)
        recording_dir = recording_path.parent
        base_name = recording_path.stem  # filename without extension

        # Check for .srt caption file
        srt_file = recording_dir / f"{base_name}.srt"
        if srt_file.exists():
            output_files[srt_file.name] = srt_file.stat().st_size

        # Check for .mp4 transcoded file
        mp4_file = recording_dir / f"{base_name}.mp4"
        if mp4_file.exists():
            output_files[mp4_file.name] = mp4_file.stat().st_size

        return output_files

    def _probe_input_duration_seconds(self, job_id_or_path: str) -> float:
        """Probe input media duration using ffprobe.

        Accepts either the recording path (preferred) or job_id which contains
        the title and timestamp; in our case we will attempt to parse the path
        from the current job ID when only job_id is available, but primarily
        this should be called with the recording path.

        Returns duration in seconds, or 0 if not available.
        """
        # If a path string was passed, use it directly
        path = None
        p = Path(job_id_or_path)
        if p.exists():
            path = str(p)
        else:
            # Not a valid path; cannot probe
            return 0.0

        try:
            # Run ffprobe to get duration
            proc = subprocess.run(
                [
                    "ffprobe",
                    "-v",
                    "error",
                    "-show_entries",
                    "format=duration",
                    "-of",
                    "default=noprint_wrappers=1:nokey=1",
                    path,
                ],
                capture_output=True,
                text=True,
                timeout=10,
            )
            if proc.returncode != 0:
                return 0.0
            out = proc.stdout.strip()
            try:
                return float(out)
            except Exception:
                return 0.0
        except Exception:
            return 0.0

    def _log_job_statistics(self, result: PipelineResult, job_id: str, log):
        """Log job completion statistics with visual divider.

        Args:
            result: PipelineResult with execution details
            job_id: Job identifier for context
        """
        if not result.success:
            return  # Only log stats for successful jobs

        # Format timing
        minutes, seconds = divmod(result.elapsed_seconds, 60)
        time_str = f"{int(minutes):02d}:{seconds:05.2f}"

        # Probe input duration for real-time factor
        # Input duration from original media
        input_duration = 0.0
        if getattr(result, "input_path", None):
            input_duration = self._probe_input_duration_seconds(result.input_path)
        if input_duration and input_duration > 0:
            rt_factor = input_duration / max(result.elapsed_seconds, 0.001)
        else:
            rt_factor = None

        # Format file sizes
        total_size = result.get_total_output_size()
        total_size_str = result.format_size(total_size)

        # Build stats lines
        divider = LOG_DIVIDER_CHAR * LOG_DIVIDER_LENGTH
        stats_lines = [
            divider,  # Visual divider
            f"Job Statistics: {job_id}",
            f"  Processing Time: {time_str}",
            f"  Total Output Size: {total_size_str}",
        ]

        # Input file size and duration
        if hasattr(result, "input_size_bytes"):
            stats_lines.append(
                f"  Input File Size: {result.format_size(result.input_size_bytes)}"
            )
        if input_duration and input_duration > 0:
            m, s = divmod(input_duration, 60)
            stats_lines.append(f"  Input Duration: {int(m):02d}:{s:05.2f}")
        if rt_factor:
            stats_lines.append(f"  Real-Time Factor: {rt_factor:.1f}x")

        # Input file size
        if hasattr(result, "input_size_bytes"):
            stats_lines.append(
                f"  Input File Size: {result.format_size(result.input_size_bytes)}"
            )

        # Add per-file statistics if multiple files
        if result.output_files:
            stats_lines.append("  Output Files:")
            for filename, size_bytes in sorted(result.output_files.items()):
                size_str = result.format_size(size_bytes)
                stats_lines.append(f"    - {filename}: {size_str}")

        stats_lines.append(divider)

        # Log as single info message (job ID will be added by formatter)
        if LOG_STATS_ENABLED:
            log.info("\n" + "\n".join(stats_lines))

    def run(
        self,
        event,
        job_id_override: Optional[str] = None,
        cancel_check: Optional[Callable[[], bool]] = None,
    ) -> PipelineResult:
        """Execute the caption command for the given event.

        Args:
            event: ProcessingEvent with path, title, etc.

        Returns:
            PipelineResult with execution details
        """
        # Set job ID for log formatting
        timestamp = getattr(event, "timestamp", None)
        timestamp_str = timestamp.strftime("%H:%M:%S") if timestamp else "UNKNOWN"
        job_id = job_id_override or f"{event.title} @ {timestamp_str}"
        log = get_logger("pipeline", job_id=job_id)

        start_time = time.time()
        try:
            # Format command with safe-quoted event path to handle spaces/special chars
            try:
                import shlex

                safe_path = shlex.quote(event.path)
            except Exception:
                safe_path = event.path  # fallback

            # Check if we're using the embed_captions module (production case)
            # If so, build command dynamically with settings from event
            # Otherwise, use the command_template (for tests and custom commands)
            # Match both: "py_captions_for_channels.embed_captions" (module)
            # and "/path/to/embed_captions.py" (direct script)
            if (
                "py_captions_for_channels.embed_captions" in self.command_template
                or "embed_captions.py" in self.command_template
            ):
                # Build command with settings from event or config
                whisper_model = getattr(event, "whisper_model", "medium")
                log_verbosity = getattr(event, "log_verbosity", "NORMAL")
                skip_caption_generation = getattr(
                    event, "skip_caption_generation", False
                )
                srt_path = getattr(event, "srt_path", None)
                if not srt_path:
                    # Default SRT path: same dir as input, basename.srt
                    import os

                    base = os.path.splitext(os.path.basename(event.path))[0]
                    srt_path = os.path.join(os.path.dirname(event.path), f"{base}.srt")

                # Shell-quote arguments safely
                def shell_quote(val):
                    return shlex.quote(str(val)) if val is not None else "''"

                # Python executable doesn't need quoting for subprocess.run(shell=True)
                python_exec = sys.executable
                options = [
                    f"--input {shell_quote(event.path)}",
                    f"--srt {shell_quote(srt_path)}",
                    f"--model {shell_quote(whisper_model)}" if whisper_model else "",
                    (
                        f"--verbosity {shell_quote(log_verbosity)}"
                        if log_verbosity
                        else ""
                    ),
                    "--skip-caption-generation" if skip_caption_generation else "",
                ]
                options_str = " ".join([opt for opt in options if opt])
                cmd = (
                    f"{python_exec} -m py_captions_for_channels.embed_captions "
                    f"{options_str}"
                )
            else:
                # Use traditional command template formatting
                # (for tests/custom commands)
                cmd = self.command_template.format(path=safe_path)

            if self.dry_run:
                log.info("[DRY-RUN] Would execute: %s", cmd)
                log.info("[DRY-RUN] Event: %s (path=%s)", event.title, event.path)
                result = PipelineResult(
                    success=True,
                    returncode=0,
                    stdout="",
                    stderr="",
                    command=cmd,
                    elapsed_seconds=0.0,
                    input_path=event.path,
                )
                # Mark result as dry-run so tracker can handle it specially
                result.is_dry_run = True
                return result

            # Visual divider at job start (configurable)
            if LOG_STATS_ENABLED:
                log.info("\n" + (LOG_DIVIDER_CHAR * LOG_DIVIDER_LENGTH))
            log.info("Running caption pipeline: %s", cmd)

            try:
                # Execute command with subprocess.run() which handles timeouts more reliably
                # than manual polling (especially for processes stuck in D state)
                log.debug("About to execute command: %s", cmd)

                try:
                    proc = subprocess.run(
                        cmd,
                        shell=True,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        text=True,
                        timeout=PIPELINE_TIMEOUT,
                    )
                    stdout = proc.stdout or ""
                    stderr = proc.stderr or ""
                except subprocess.TimeoutExpired as e:
                    log.error(
                        "Caption pipeline timed out for %s after %d seconds",
                        event.path,
                        PIPELINE_TIMEOUT,
                    )
                    elapsed = time.time() - start_time
                    return PipelineResult(
                        success=False,
                        returncode=-1,
                        stdout=e.stdout or "",
                        stderr=f"Command timed out after {PIPELINE_TIMEOUT} seconds",
                        command=cmd,
                        elapsed_seconds=elapsed,
                        input_path=event.path,
                    )

                if proc.returncode != 0:
                    elapsed = time.time() - start_time
                    log.error(
                        "Caption pipeline failed for %s (exit code %d)",
                        event.path,
                        proc.returncode,
                    )
                    log.error("Command attempted: %s", cmd)
                    if proc.returncode == 126:
                        log.error(
                            "Exit code 126: Permission denied or not executable. "
                            "Check permissions and shebang for: %s",
                            cmd,
                        )
                    if stderr:
                        log.error("stderr: %s", stderr[:500])
                    return PipelineResult(
                        success=False,
                        returncode=proc.returncode,
                        stdout=stdout,
                        stderr=stderr,
                        command=cmd,
                        elapsed_seconds=elapsed,
                        input_path=event.path,
                    )
                else:
                    log.info("Caption pipeline completed for %s", event.path)
                    # Log whisper's output for debugging
                    if stdout:
                        log.debug("stdout: %s", stdout[-1000:])
                    if stderr:
                        log.info("whisper output: %s", stderr[-500:])

                    # Collect output file statistics
                    elapsed = time.time() - start_time
                    output_files = self._collect_output_files(event.path)
                    # Parse ffmpeg speed if present
                    ffmpeg_speed = None
                    m = re.search(r"speed=([0-9.]+)x", stderr)
                    if m:
                        ffmpeg_speed = float(m.group(1))
                    try:
                        input_size = Path(event.path).stat().st_size
                    except Exception:
                        input_size = 0

                    return PipelineResult(
                        success=True,
                        returncode=0,
                        stdout=stdout,
                        stderr=stderr,
                        command=cmd,
                        elapsed_seconds=elapsed,
                        output_files=output_files,
                        input_size_bytes=input_size,
                        input_path=event.path,
                    )

                    # If ffmpeg speed parsed, log it for reference
                    if ffmpeg_speed is not None:
                        log.info(
                            "Transcode speed reported by ffmpeg: %.2fx", ffmpeg_speed
                        )

            except Exception as e:
                elapsed = time.time() - start_time
                log.error("Exception running caption pipeline: %s", e)
                log.error("Command attempted: %s", cmd)
                return PipelineResult(
                    success=False,
                    returncode=-1,
                    stdout="",
                    stderr=str(e),
                    command=cmd,
                    elapsed_seconds=elapsed,
                    input_path=event.path,
                )
        finally:
            pass  # No job_id context to clear with new logger
